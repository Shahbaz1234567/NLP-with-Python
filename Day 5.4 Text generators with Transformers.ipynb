{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "446b6ff8",
   "metadata": {},
   "source": [
    "# Text Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee665dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "655ea0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(prompt):\n",
    "    text_generator=pipeline('text-generation')\n",
    "    generated_text=text_generator(prompt,max_length=5000,num_return_sequences=1)[0]\n",
    "    #print(generated_text)\n",
    "    return generated_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5fc5b0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User prompt>> Hope you are doing great\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to gpt2 and revision 6c0e608 (https://huggingface.co/gpt2).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca4897c8b5b24f4db70347ca6214a350",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:133: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\shabaz\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "613351ad67b240c4b0faf92c616adeed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d43074b0f2514b7cac3e38423dce8c0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abc42e37b4ba48d5a366184d78d7cfab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3dc48af51f7040fd86f61374778bb55a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "654a02430e284a6d9e90194167d61c8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'generated_text': 'Hope you are doing great on the show\\n\\nI am getting sick of not being able to enjoy a good meal\\n\\nNo matter what you eat, I do not want you to get sick of me\\n\\n(I\\'m not mad, I\\'m joking. I mean, I am saying that.)\\n\\nI just wish that you were just trying to stop me from killing me\\n\\nI don\\'t even know if it was an accident or if you knew when to hit me with it the first day\\n\\nI am a bit sick now, but I am a part of you because of the love you are putting aside for me\\n\\nI just want you to know that I am grateful for where you are going and how that can change\\n\\nYou made me feel wonderful about what I have done for you\\n\\nThat\\'s why I am the best person I know and what I want in life\\n\\nNo one can take away everything from me, so thank you\\n\\nYou are great and you\\'re great when you do what you do\\n\\nPeople are going to keep getting fed up of what can be done better and can go, but they will NOT stop because I am on the way\\n\\nThanks to both you, the \"people\" and the people who are going to be eating now\\n\\nPlease tell everyone we did not make you happy. We were just working together to make sure we all get the food we want\\n\\nAnd we are going to continue to do it\\n\\nYes, the food is too great to ignore if we are lucky, but we are going to continue to help people in need without even realizing what we are all doing...\\n\\nDo you have a good, loving, good man or a bad, loving, bad man? We are going to see.\\n\\n-The Ultimate Guide to Getting Ready for the Workout -'}\n"
     ]
    }
   ],
   "source": [
    "text_gen=generate_text(input('User prompt>> '))\n",
    "print(text_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0195fe45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
