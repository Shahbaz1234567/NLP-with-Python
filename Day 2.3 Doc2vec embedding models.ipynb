{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e562facc",
   "metadata": {},
   "source": [
    "# Doc2Vec:\n",
    "    \n",
    "Doc2vec is an extension of Word2vec\n",
    "\n",
    "Concepts:\n",
    "1. PV-DM(Distributed model)\n",
    "2. PV-DBOW(Distributed Bag of words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85d3297e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TaggedDocument(words=['word', 'embeddings', 'capture', 'semantic', 'relationships', '.'], tags=['0']), TaggedDocument(words=['word2vec', 'is', 'a', 'popular', 'technique', 'in', 'nlp'], tags=['1']), TaggedDocument(words=['word', 'embedding', 'model', 'in', 'a', 'continuos', 'vector', 'space'], tags=['2'])]\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Doc2Vec\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "from nltk.tokenize import word_tokenize\n",
    "#sample text\n",
    "documents=['Word embeddings capture semantic relationships.',\n",
    "           'Word2vec is a popular technique in nlp',\n",
    "           'Word embedding model in a continuos vector space']\n",
    "#Tokenize & tag documents\n",
    "tagged_data=[TaggedDocument(words=word_tokenize(doc.lower()),tags=[str(i)]) for i,doc in enumerate(documents)]\n",
    "print(tagged_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5e50aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train Doc2vec model\n",
    "model=Doc2Vec(vector_size=100,window=2,min_count=1,workers=5,epochs=20)\n",
    "model.build_vocab(tagged_data)\n",
    "model.train(tagged_data,total_examples=model.corpus_count,epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78c07d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_doc_1=model.infer_vector(word_tokenize(\"Word embeddings capture semantic relation\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b903b415",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.5279885e-03, -9.9850690e-04,  2.7232795e-04, -2.9513596e-03,\n",
       "       -4.6969024e-03,  3.2790299e-03, -3.3828181e-03, -3.1424188e-03,\n",
       "       -3.0997166e-04, -4.0712836e-03, -4.1918140e-03,  4.2506307e-03,\n",
       "       -1.6440435e-03,  6.6861376e-04, -1.7682081e-03,  3.5665294e-03,\n",
       "        1.3013239e-03,  3.1250678e-03,  4.4974820e-03, -2.9628291e-03,\n",
       "        3.2059434e-03,  2.6109407e-03, -4.4054952e-03,  4.1160844e-03,\n",
       "       -3.0168113e-03,  4.8914626e-03, -3.8569081e-03, -1.5252280e-03,\n",
       "        4.2748991e-03,  4.0028063e-03,  4.5701526e-03,  3.8155555e-04,\n",
       "        3.6424282e-03,  2.9265536e-03,  2.8427190e-03, -6.0105795e-04,\n",
       "        1.3413741e-03,  9.0766890e-04,  2.3489713e-03, -9.4353553e-04,\n",
       "       -3.6188847e-04, -1.2603049e-03, -9.3865994e-04,  3.9095711e-03,\n",
       "        2.8401553e-03,  1.7476442e-03, -2.1629834e-03,  1.4895867e-03,\n",
       "        3.7823638e-03, -1.2908645e-03,  1.8818652e-04, -2.4702464e-04,\n",
       "       -7.1926083e-04, -3.6576453e-03, -1.7188290e-03, -8.4332016e-05,\n",
       "       -2.4845442e-03, -1.0411099e-03,  1.6309004e-03, -3.6284204e-03,\n",
       "       -2.2176732e-03, -1.1847417e-03, -1.1175311e-03, -4.2092702e-03,\n",
       "       -4.1076578e-03,  2.4860008e-03, -3.1882909e-03,  1.5902868e-03,\n",
       "       -2.6103952e-03, -1.7705515e-03,  1.0975704e-03, -3.2014453e-03,\n",
       "        2.6907253e-03, -2.8053278e-03, -2.1996701e-03, -1.6266649e-03,\n",
       "       -3.4166870e-03,  5.4101914e-04,  2.1938444e-03,  3.5329545e-03,\n",
       "       -1.8940429e-03,  2.4646455e-03, -3.7945085e-04, -3.5995552e-03,\n",
       "       -1.5674048e-03,  4.2365231e-03, -2.8092761e-03, -4.6773078e-03,\n",
       "        2.7143927e-03, -4.8172167e-03, -2.9945557e-04, -4.3848084e-04,\n",
       "       -1.4022810e-03, -4.3973653e-03, -3.8619407e-03,  5.0437171e-03,\n",
       "        8.9812261e-04, -4.7074808e-03, -2.4355645e-03, -4.4268039e-03],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_doc_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21532d34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shabaz\\AppData\\Local\\Temp\\ipykernel_2660\\81474329.py:2: DeprecationWarning: Call to deprecated `docvecs` (The `docvecs` property has been renamed `dv`.).\n",
      "  similar_doc=model.docvecs.most_similar(positive=[vector_doc_1])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vector for 'Word embeddings capture semantic relationships.':[ 2.5279885e-03 -9.9850690e-04  2.7232795e-04 -2.9513596e-03\n",
      " -4.6969024e-03  3.2790299e-03 -3.3828181e-03 -3.1424188e-03\n",
      " -3.0997166e-04 -4.0712836e-03 -4.1918140e-03  4.2506307e-03\n",
      " -1.6440435e-03  6.6861376e-04 -1.7682081e-03  3.5665294e-03\n",
      "  1.3013239e-03  3.1250678e-03  4.4974820e-03 -2.9628291e-03\n",
      "  3.2059434e-03  2.6109407e-03 -4.4054952e-03  4.1160844e-03\n",
      " -3.0168113e-03  4.8914626e-03 -3.8569081e-03 -1.5252280e-03\n",
      "  4.2748991e-03  4.0028063e-03  4.5701526e-03  3.8155555e-04\n",
      "  3.6424282e-03  2.9265536e-03  2.8427190e-03 -6.0105795e-04\n",
      "  1.3413741e-03  9.0766890e-04  2.3489713e-03 -9.4353553e-04\n",
      " -3.6188847e-04 -1.2603049e-03 -9.3865994e-04  3.9095711e-03\n",
      "  2.8401553e-03  1.7476442e-03 -2.1629834e-03  1.4895867e-03\n",
      "  3.7823638e-03 -1.2908645e-03  1.8818652e-04 -2.4702464e-04\n",
      " -7.1926083e-04 -3.6576453e-03 -1.7188290e-03 -8.4332016e-05\n",
      " -2.4845442e-03 -1.0411099e-03  1.6309004e-03 -3.6284204e-03\n",
      " -2.2176732e-03 -1.1847417e-03 -1.1175311e-03 -4.2092702e-03\n",
      " -4.1076578e-03  2.4860008e-03 -3.1882909e-03  1.5902868e-03\n",
      " -2.6103952e-03 -1.7705515e-03  1.0975704e-03 -3.2014453e-03\n",
      "  2.6907253e-03 -2.8053278e-03 -2.1996701e-03 -1.6266649e-03\n",
      " -3.4166870e-03  5.4101914e-04  2.1938444e-03  3.5329545e-03\n",
      " -1.8940429e-03  2.4646455e-03 -3.7945085e-04 -3.5995552e-03\n",
      " -1.5674048e-03  4.2365231e-03 -2.8092761e-03 -4.6773078e-03\n",
      "  2.7143927e-03 -4.8172167e-03 -2.9945557e-04 -4.3848084e-04\n",
      " -1.4022810e-03 -4.3973653e-03 -3.8619407e-03  5.0437171e-03\n",
      "  8.9812261e-04 -4.7074808e-03 -2.4355645e-03 -4.4268039e-03]\n",
      "\n",
      "Most similar document:[('0', 0.04573233425617218), ('1', 0.015703260898590088), ('2', -0.07673916965723038)]\n"
     ]
    }
   ],
   "source": [
    "#find the most similar document\n",
    "similar_doc=model.docvecs.most_similar(positive=[vector_doc_1])\n",
    "print(f\"vector for 'Word embeddings capture semantic relationships.':{vector_doc_1}\")\n",
    "print()\n",
    "print(f\"Most similar document:{similar_doc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9a1eb1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
