{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b36f2974",
   "metadata": {},
   "source": [
    "# Word2vec:\n",
    "    \n",
    "1. Word embedding method\n",
    "2. Developed by google researchers\n",
    "3. Captures semantic relation between words\n",
    "\n",
    "works:\n",
    "1. CBOW-Continuous bag of words\n",
    "2. Skip gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64328fd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: gensim in c:\\programdata\\anaconda3\\lib\\site-packages (4.3.0)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from gensim) (1.24.3)\n",
      "Requirement already satisfied: scipy>=1.7.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from gensim) (1.11.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from gensim) (5.2.1)\n",
      "Collecting FuzzyTM>=0.4.0 (from gensim)\n",
      "  Downloading FuzzyTM-2.0.5-py3-none-any.whl (29 kB)\n",
      "Requirement already satisfied: pandas in c:\\programdata\\anaconda3\\lib\\site-packages (from FuzzyTM>=0.4.0->gensim) (2.0.3)\n",
      "Collecting pyfume (from FuzzyTM>=0.4.0->gensim)\n",
      "  Downloading pyFUME-0.2.25-py3-none-any.whl (67 kB)\n",
      "     ---------------------------------------- 0.0/67.1 kB ? eta -:--:--\n",
      "     ----------------------------------- --- 61.4/67.1 kB 1.7 MB/s eta 0:00:01\n",
      "     ----------------------------------- --- 61.4/67.1 kB 1.7 MB/s eta 0:00:01\n",
      "     ------------------------------------- 67.1/67.1 kB 605.2 kB/s eta 0:00:00\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas->FuzzyTM>=0.4.0->gensim) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas->FuzzyTM>=0.4.0->gensim) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas->FuzzyTM>=0.4.0->gensim) (2023.3)\n",
      "Collecting simpful (from pyfume->FuzzyTM>=0.4.0->gensim)\n",
      "  Obtaining dependency information for simpful from https://files.pythonhosted.org/packages/8d/93/8448d3f1aa9d2911b8cba2602aaa1af85eb31a26d28b7b737f1fa5b40c02/simpful-2.11.1-py3-none-any.whl.metadata\n",
      "  Downloading simpful-2.11.1-py3-none-any.whl.metadata (4.8 kB)\n",
      "Collecting fst-pso (from pyfume->FuzzyTM>=0.4.0->gensim)\n",
      "  Downloading fst-pso-1.8.1.tar.gz (18 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->FuzzyTM>=0.4.0->gensim) (1.16.0)\n",
      "Collecting miniful (from fst-pso->pyfume->FuzzyTM>=0.4.0->gensim)\n",
      "  Downloading miniful-0.0.6.tar.gz (2.8 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Downloading simpful-2.11.1-py3-none-any.whl (32 kB)\n",
      "Building wheels for collected packages: fst-pso, miniful\n",
      "  Building wheel for fst-pso (setup.py): started\n",
      "  Building wheel for fst-pso (setup.py): finished with status 'done'\n",
      "  Created wheel for fst-pso: filename=fst_pso-1.8.1-py3-none-any.whl size=20448 sha256=aee530beff56bdf7f0113f9a57a9b51319eb6c6311c9b8fd08215d6fff41aa55\n",
      "  Stored in directory: c:\\users\\shabaz\\appdata\\local\\pip\\cache\\wheels\\69\\f5\\e5\\18ad53fe1ed6b2af9fad05ec052e4acbac8e92441df44bad2e\n",
      "  Building wheel for miniful (setup.py): started\n",
      "  Building wheel for miniful (setup.py): finished with status 'done'\n",
      "  Created wheel for miniful: filename=miniful-0.0.6-py3-none-any.whl size=3522 sha256=9217e75197fffdee1b47156f3a36a0f8922ec743eb81def89ea9e1e162bd2ae2\n",
      "  Stored in directory: c:\\users\\shabaz\\appdata\\local\\pip\\cache\\wheels\\9d\\ff\\2f\\afe4cd56f47de147407705626517d68bea0f3b74eb1fb168e6\n",
      "Successfully built fst-pso miniful\n",
      "Installing collected packages: simpful, miniful, fst-pso, pyfume, FuzzyTM\n",
      "Successfully installed FuzzyTM-2.0.5 fst-pso-1.8.1 miniful-0.0.6 pyfume-0.2.25 simpful-2.11.1\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ab16733",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector for 'semantic':[ 0.00609409 -0.04229162 -0.04111972 -0.00115508  0.00618644 -0.0287169\n",
      " -0.02362637 -0.03673037  0.04164308  0.00060649 -0.022547    0.02850853\n",
      "  0.04590008 -0.02049936  0.03982341  0.02687717  0.02939562  0.00256295\n",
      "  0.04106542 -0.0350952 ]\n",
      "====================================================================================================\n",
      "Vector for 'nlp':[-0.04309844  0.01832869  0.02594942  0.02870969  0.03733459 -0.03083838\n",
      "  0.00552807  0.03023641 -0.01420025 -0.03086761 -0.00205112 -0.04184474\n",
      " -0.02800006  0.03552269  0.0167627   0.03612835  0.03400124  0.03765371\n",
      " -0.01894577 -0.00280903]\n",
      "====================================================================================================\n",
      "Similarity b/w 'word' and 'embeddings':0.07046516239643097\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "#sample text\n",
    "text=['Word embeddings capture semantic relationships.',\n",
    "         'Word2vec is a popular technique in nlp',\n",
    "         'Word embedding model in a continuos vector space']\n",
    "tokenized_text=[word_tokenize(sentence.lower()) for sentence in text]\n",
    "\n",
    "#Train Word2vec model\n",
    "\n",
    "model=Word2Vec(sentences=tokenized_text,vector_size=20,window=5,min_count=1,workers=4)\n",
    "#Find word vectors\n",
    "vector_semantic=model.wv['semantic']\n",
    "vector_nlp=model.wv['nlp']\n",
    "#similarity b/w words\n",
    "similarity=model.wv.similarity('word','embeddings')\n",
    "print(f\"Vector for 'semantic':{vector_semantic}\")\n",
    "print('='*100)\n",
    "print(f\"Vector for 'nlp':{vector_nlp}\")\n",
    "print('='*100)\n",
    "print(f\"Similarity b/w 'word' and 'embeddings':{similarity}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d262d238",
   "metadata": {},
   "source": [
    "# Word2vec Hyperparameter:\n",
    "    \n",
    "1. Vector_size : Features(words)/dimensionality of word- Default: 100/300 dimensions\n",
    "\n",
    "2. window_size:\n",
    " Size of the context window\n",
    " Maximum distance the current and predicted word within the sentence\n",
    " Default: 5 for word2vec\n",
    " \n",
    "3.min_count:\n",
    " * Specifies the minimum frequency threshold of a word\n",
    " * Default : 5 for word2vec\n",
    " \n",
    "4.workers:\n",
    " * Number of CPU cores to use for training the model\n",
    " \n",
    "5. sg(skip-gram):\n",
    " sg=0 - indicates, it is uses CBOW to train the model\n",
    " sg=1 - skip-gram is used to train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b9cc48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
